{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce591861",
   "metadata": {},
   "source": [
    "# Arbiscan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4bfa896",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 40/40 [09:46<00:00, 14.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted features for 56896 addresses.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "# Подавить предупреждения от numpy и pandas о пустых срезах\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "\n",
    "# ===== Функция для извлечения признаков одного адреса =====\n",
    "def extract_sybil_features_arbiscan(df: pd.DataFrame) -> dict:\n",
    "    df = df.copy()\n",
    "    # Конвертация числовых полей\n",
    "    num_cols = [\n",
    "        \"blockNumber\",\n",
    "        \"nonce\",\n",
    "        \"transactionIndex\",\n",
    "        \"value\",\n",
    "        \"gas\",\n",
    "        \"gasPrice\",\n",
    "        \"gasPriceBid\",\n",
    "        \"cumulativeGasUsed\",\n",
    "        \"gasUsed\",\n",
    "        \"confirmations\",\n",
    "        \"isError\",\n",
    "    ]\n",
    "    for col in num_cols:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\").fillna(0)\n",
    "\n",
    "    # Преобразование timestamp\n",
    "    df[\"timeStamp\"] = pd.to_numeric(df[\"timeStamp\"], errors=\"coerce\")\n",
    "    df[\"timeStamp\"] = pd.to_datetime(df[\"timeStamp\"], unit=\"s\", errors=\"coerce\")\n",
    "    df = df.sort_values(\"timeStamp\").reset_index(drop=True)\n",
    "\n",
    "    # Фильтрация по дате\n",
    "    cutoff = pd.Timestamp(\"2024-06-20\")\n",
    "    df = df[df[\"timeStamp\"] < cutoff]\n",
    "    if df.empty:\n",
    "        return {}  # нет транзакций до cutoff\n",
    "\n",
    "    addr = df[\"address\"].iloc[0].lower()\n",
    "    features = {}\n",
    "\n",
    "    # ===== Базовые счётчики =====\n",
    "    tx_count = len(df)\n",
    "    days_active = df[\"timeStamp\"].dt.date.nunique()\n",
    "    features[\"tx_count\"] = tx_count\n",
    "    features[\"active_days\"] = days_active\n",
    "    features[\"lifetime_days\"] = (\n",
    "        (df[\"timeStamp\"].max() - df[\"timeStamp\"].min()).total_seconds() / 86400\n",
    "        if tx_count > 1\n",
    "        else 0.0\n",
    "    )\n",
    "\n",
    "    # ===== Интервалы между транзакциями =====\n",
    "    df[\"time_diff\"] = df[\"timeStamp\"].diff().dt.total_seconds()\n",
    "    features.update(\n",
    "        {\n",
    "            \"mean_tx_interval\": df[\"time_diff\"].mean(),\n",
    "            \"median_tx_interval\": df[\"time_diff\"].median(),\n",
    "            \"std_tx_interval\": df[\"time_diff\"].std(),\n",
    "            \"max_tx_interval\": df[\"time_diff\"].max(),\n",
    "            \"fast_tx_ratio\": (df[\"time_diff\"] < 1).mean(),\n",
    "            \"short_interval_ratio\": (df[\"time_diff\"] < 60).mean(),\n",
    "            \"tx_per_day\": tx_count / days_active if days_active > 0 else tx_count,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # ===== Блок/nonce метрики =====\n",
    "    block_diff = df[\"blockNumber\"].diff().fillna(0)\n",
    "    nonce_diff = df[\"nonce\"].diff().fillna(0)\n",
    "    features.update(\n",
    "        {\n",
    "            \"mean_block_gap\": block_diff.mean(),\n",
    "            \"std_block_gap\": block_diff.std(),\n",
    "            \"mean_nonce_gap\": nonce_diff.mean(),\n",
    "            \"max_nonce_gap\": nonce_diff.max(),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # ===== Статистики значений переводов =====\n",
    "    df[\"value_eth\"] = df[\"value\"] / 1e18\n",
    "    v = df[\"value_eth\"]\n",
    "    features.update(\n",
    "        {\n",
    "            \"total_value_eth\": v.sum(),\n",
    "            \"mean_value_eth\": v.mean(),\n",
    "            \"median_value_eth\": v.median(),\n",
    "            \"std_value_eth\": v.std(),\n",
    "            \"min_value_eth\": v.min(),\n",
    "            \"max_value_eth\": v.max(),\n",
    "            \"zero_value_tx_ratio\": (v == 0).mean(),\n",
    "        }\n",
    "    )\n",
    "    if tx_count > 0:\n",
    "        vc = v.value_counts()\n",
    "        top_val, top_freq = vc.index[0], vc.iloc[0]\n",
    "        q1, q3 = v.quantile([0.25, 0.75])\n",
    "        probs = vc / tx_count\n",
    "        features.update(\n",
    "            {\n",
    "                \"most_common_value\": top_val,\n",
    "                \"most_common_value_freq\": top_freq,\n",
    "                \"most_common_value_ratio\": top_freq / tx_count,\n",
    "                \"value_entropy\": -(probs * np.log(probs + 1e-9)).sum(),\n",
    "                \"below_q1_ratio\": (v < q1).mean(),\n",
    "                \"above_q3_ratio\": (v > q3).mean(),\n",
    "                \"value_skew\": v.skew(),\n",
    "                \"value_kurtosis\": v.kurtosis(),\n",
    "                \"value_gini\": (\n",
    "                    2\n",
    "                    * (np.arange(1, len(v) + 1) * np.sort(v)).sum()\n",
    "                    / (len(v) * v.sum())\n",
    "                    - (len(v) + 1) / len(v)\n",
    "                ),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # ===== Потоки средств =====\n",
    "    out_vals = df[df[\"from\"].str.lower() == addr][\"value_eth\"]\n",
    "    in_vals = df[df[\"to\"].str.lower() == addr][\"value_eth\"]\n",
    "    features.update(\n",
    "        {\n",
    "            \"outgoing_value_eth\": out_vals.sum(),\n",
    "            \"incoming_value_eth\": in_vals.sum(),\n",
    "            \"net_value_eth\": in_vals.sum() - out_vals.sum(),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # ===== Газ =====\n",
    "    df[\"gas_eth\"] = df[\"gasPrice\"] * df[\"gasUsed\"] / 1e18\n",
    "    g = df[\"gas_eth\"]\n",
    "    gp = df[\"gasPrice\"]\n",
    "    bid = df[\"gasPriceBid\"]\n",
    "    gas_used_ratio = np.where(df[\"gas\"] > 0, df[\"gasUsed\"] / df[\"gas\"], np.nan)\n",
    "    features.update(\n",
    "        {\n",
    "            \"total_gas_eth\": g.sum(),\n",
    "            \"mean_gas_eth\": g.mean(),\n",
    "            \"std_gas_eth\": g.std(),\n",
    "            \"mean_gas_price\": gp.mean(),\n",
    "            \"std_gas_price\": gp.std(),\n",
    "            \"mean_gas_bid_ratio\": np.nanmean(bid / gp),\n",
    "            \"gas_used_ratio_mean\": np.nanmean(gas_used_ratio),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # ===== Ошибки и направления =====\n",
    "    errs = df[\"isError\"].astype(int)\n",
    "    out = df[df[\"from\"].str.lower() == addr]\n",
    "    inc = df[df[\"to\"].str.lower() == addr]\n",
    "    features.update(\n",
    "        {\n",
    "            \"tx_errors\": errs.sum(),\n",
    "            \"error_ratio\": errs.mean(),\n",
    "            \"outgoing_tx_count\": len(out),\n",
    "            \"incoming_tx_count\": len(inc),\n",
    "            \"unique_receivers\": out[\"to\"].nunique(),\n",
    "            \"unique_senders\": inc[\"from\"].nunique(),\n",
    "            \"out_in_ratio\": len(out) / len(inc) if len(inc) > 0 else np.nan,\n",
    "            \"receiver_per_tx\": (out[\"to\"].nunique() / len(out))\n",
    "            if len(out) > 0\n",
    "            else np.nan,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # ===== Токены и контракты =====\n",
    "    tokens = df[df[\"tokenSymbol\"].notna()]\n",
    "    features.update(\n",
    "        {\n",
    "            \"token_tx_count\": len(tokens),\n",
    "            \"token_tx_ratio\": len(tokens) / tx_count if tx_count > 0 else 0,\n",
    "            \"unique_tokens\": tokens[\"tokenSymbol\"].nunique(),\n",
    "            \"unique_contracts\": df[\"contractAddress\"].nunique(),\n",
    "            \"distinct_contract_ratio\": df[\"contractAddress\"].nunique() / tx_count\n",
    "            if tx_count > 0\n",
    "            else 0,\n",
    "            \"unique_methods\": df[\"functionName\"].nunique(),\n",
    "            \"unique_methodIds\": df[\"methodId\"].nunique(),\n",
    "            \"contract_call_ratio\": (df[\"input\"].astype(str) != \"0x\").mean(),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # ===== Повторы транзакций =====\n",
    "    dup_cols = [\"to\", \"value\", \"gas\", \"gasPrice\", \"functionName\"]\n",
    "    dup_count = df.duplicated(subset=dup_cols).sum()\n",
    "    features.update(\n",
    "        {\n",
    "            \"duplicate_tx_count\": dup_count,\n",
    "            \"duplicate_tx_ratio\": dup_count / tx_count if tx_count > 0 else 0,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # ===== Время суток и типы транзакций =====\n",
    "    hours = df[\"timeStamp\"].dt.hour.dropna()\n",
    "    hour_probs = hours.value_counts(normalize=True)\n",
    "    type_probs = df[\"tx_type\"].dropna().value_counts(normalize=True)\n",
    "    features.update(\n",
    "        {\n",
    "            \"peak_hour\": hour_probs.idxmax() if not hour_probs.empty else np.nan,\n",
    "            \"peak_hour_ratio\": hour_probs.max() if not hour_probs.empty else np.nan,\n",
    "            \"hour_entropy\": -(hour_probs * np.log(hour_probs + 1e-9)).sum()\n",
    "            if not hour_probs.empty\n",
    "            else np.nan,\n",
    "            \"weekend_tx_ratio\": (df[\"timeStamp\"].dt.weekday >= 5).mean(),\n",
    "            \"unique_tx_types\": df[\"tx_type\"].nunique(),\n",
    "            \"tx_type_entropy\": -(type_probs * np.log(type_probs + 1e-9)).sum()\n",
    "            if not type_probs.empty\n",
    "            else np.nan,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # ===== Подтверждения =====\n",
    "    conf = df[\"confirmations\"]\n",
    "    features.update(\n",
    "        {\n",
    "            \"confirmations_mean\": conf.mean(),\n",
    "            \"confirmations_std\": conf.std(),\n",
    "            \"low_conf_ratio\": (conf < conf.quantile(0.25)).mean()\n",
    "            if len(conf) > 0\n",
    "            else np.nan,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "# ===== Функция для обработки всех .pkl файлов и агрегации с пропуском пустых и прогрессом =====\n",
    "def process_pickles(folder_path: str) -> pd.DataFrame:\n",
    "    features_list = []\n",
    "    pkl_files = [f for f in os.listdir(folder_path) if f.endswith(\".pkl\")]\n",
    "    for fname in tqdm(pkl_files, desc=\"Processing files\"):\n",
    "        file_path = os.path.join(folder_path, fname)\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            list_of_dfs = pickle.load(f)\n",
    "        for df in tqdm(list_of_dfs, desc=f\"File {fname}\", leave=False):\n",
    "            for addr in df[\"address\"].unique():\n",
    "                subdf = df[df[\"address\"] == addr]\n",
    "                feats = extract_sybil_features_arbiscan(subdf)\n",
    "                if not feats:  # пропустить адреса без транзакций до cutoff\n",
    "                    continue\n",
    "                feats[\"address\"] = addr\n",
    "                features_list.append(feats)\n",
    "    return pd.DataFrame(features_list)\n",
    "\n",
    "\n",
    "# ===== Пример запуска =====\n",
    "if __name__ == \"__main__\":\n",
    "    folder = \"arbiscan_txns\"\n",
    "    all_features_df = process_pickles(folder)\n",
    "    all_features_df.to_pickle(\"sybil_features_all_addresses.pickle\")\n",
    "    print(f\"Extracted features for {len(all_features_df)} addresses.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b3ff8b",
   "metadata": {},
   "source": [
    "# Etherscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eddade5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 25/25 [06:01<00:00, 14.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted features for 19740 addresses.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# Подавить предупреждения от numpy и pandas о пустых срезах\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "\n",
    "def extract_sybil_features_etherscan(df: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    Извлекает статистические признаки для одного адреса из DataFrame транзакций Etherscan.\n",
    "    Колонки могут частично отсутствовать — функции это не сломает.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    cols = set(df.columns)\n",
    "\n",
    "    # ===== Приведение типов =====\n",
    "    num_cols = [\n",
    "        \"blockNumber\",\n",
    "        \"nonce\",\n",
    "        \"transactionIndex\",\n",
    "        \"value\",\n",
    "        \"gas\",\n",
    "        \"gasPrice\",\n",
    "        \"cumulativeGasUsed\",\n",
    "        \"gasUsed\",\n",
    "        \"confirmations\",\n",
    "        \"isError\",\n",
    "        \"txreceipt_status\",\n",
    "        \"errCode\",\n",
    "        \"tokenDecimal\",\n",
    "    ]\n",
    "    for col in num_cols:\n",
    "        if col in cols:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\").fillna(0)\n",
    "\n",
    "    # timestamp → datetime\n",
    "    if \"timeStamp\" in cols:\n",
    "        df[\"timeStamp\"] = pd.to_numeric(df[\"timeStamp\"], errors=\"coerce\")\n",
    "        df[\"timeStamp\"] = pd.to_datetime(df[\"timeStamp\"], unit=\"s\", errors=\"coerce\")\n",
    "        df = df.sort_values(\"timeStamp\").reset_index(drop=True)\n",
    "    else:\n",
    "        return {}\n",
    "\n",
    "    # Фильтрация по дате\n",
    "    cutoff = pd.Timestamp(\"2024-06-20\")\n",
    "    df = df[df[\"timeStamp\"] < cutoff]\n",
    "    if df.empty:\n",
    "        return {}\n",
    "\n",
    "    addr = df[\"address\"].iloc[0].lower()\n",
    "    features = {}\n",
    "\n",
    "    # ===== Базовые счётчики =====\n",
    "    tx_count = len(df)\n",
    "    days_active = df[\"timeStamp\"].dt.date.nunique()\n",
    "    lifetime = (\n",
    "        (df[\"timeStamp\"].max() - df[\"timeStamp\"].min()).total_seconds() / 86400\n",
    "        if tx_count > 1\n",
    "        else 0.0\n",
    "    )\n",
    "    features.update(\n",
    "        {\"tx_count\": tx_count, \"active_days\": days_active, \"lifetime_days\": lifetime}\n",
    "    )\n",
    "\n",
    "    # ===== Интервалы между Tx =====\n",
    "    df[\"time_diff\"] = df[\"timeStamp\"].diff().dt.total_seconds()\n",
    "    features.update(\n",
    "        {\n",
    "            \"mean_tx_interval\": df[\"time_diff\"].mean(),\n",
    "            \"median_tx_interval\": df[\"time_diff\"].median(),\n",
    "            \"std_tx_interval\": df[\"time_diff\"].std(),\n",
    "            \"max_tx_interval\": df[\"time_diff\"].max(),\n",
    "            \"fast_tx_ratio\": (df[\"time_diff\"] < 1).mean(),\n",
    "            \"short_interval_ratio\": (df[\"time_diff\"] < 60).mean(),\n",
    "            \"tx_per_day\": tx_count / days_active if days_active else float(tx_count),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # ===== Блок и nonce =====\n",
    "    features.update(\n",
    "        {\n",
    "            \"mean_block_gap\": df[\"blockNumber\"].diff().fillna(0).mean(),\n",
    "            \"std_block_gap\": df[\"blockNumber\"].diff().fillna(0).std(),\n",
    "            \"mean_nonce_gap\": df[\"nonce\"].diff().fillna(0).mean(),\n",
    "            \"max_nonce_gap\": df[\"nonce\"].diff().fillna(0).max(),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # ===== ETH-значения =====\n",
    "    df[\"value_eth\"] = df[\"value\"] / 1e18\n",
    "    v = df[\"value_eth\"]\n",
    "    features.update(\n",
    "        {\n",
    "            \"total_value_eth\": v.sum(),\n",
    "            \"mean_value_eth\": v.mean(),\n",
    "            \"median_value_eth\": v.median(),\n",
    "            \"std_value_eth\": v.std(),\n",
    "            \"min_value_eth\": v.min(),\n",
    "            \"max_value_eth\": v.max(),\n",
    "            \"zero_value_tx_ratio\": (v == 0).mean(),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if tx_count:\n",
    "        vc = v.value_counts()\n",
    "        top_val, top_freq = vc.index[0], vc.iloc[0]\n",
    "        probs = vc / tx_count\n",
    "        q1, q3 = v.quantile([0.25, 0.75])\n",
    "        features.update(\n",
    "            {\n",
    "                \"most_common_value\": top_val,\n",
    "                \"most_common_value_freq\": top_freq,\n",
    "                \"most_common_value_ratio\": top_freq / tx_count,\n",
    "                \"value_entropy\": -(probs * np.log(probs + 1e-9)).sum(),\n",
    "                \"below_q1_ratio\": (v < q1).mean(),\n",
    "                \"above_q3_ratio\": (v > q3).mean(),\n",
    "                \"value_skew\": v.skew(),\n",
    "                \"value_kurtosis\": v.kurtosis(),\n",
    "                \"value_gini\": (\n",
    "                    2\n",
    "                    * (np.arange(1, len(v) + 1) * np.sort(v)).sum()\n",
    "                    / (len(v) * v.sum())\n",
    "                    - (len(v) + 1) / len(v)\n",
    "                ),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # ===== Потоки ETH =====\n",
    "    out_vals = df[df[\"from\"].str.lower() == addr][\"value_eth\"]\n",
    "    in_vals = df[df[\"to\"].str.lower() == addr][\"value_eth\"]\n",
    "    features.update(\n",
    "        {\n",
    "            \"outgoing_value_eth\": out_vals.sum(),\n",
    "            \"incoming_value_eth\": in_vals.sum(),\n",
    "            \"net_value_eth\": in_vals.sum() - out_vals.sum(),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # ===== Газ =====\n",
    "    df[\"gas_eth\"] = (\n",
    "        df[\"gasPrice\"] * df[\"gasUsed\"] / 1e18 if {\"gasPrice\", \"gasUsed\"} <= cols else 0\n",
    "    )\n",
    "    g = df[\"gas_eth\"] if \"gas_eth\" in df else pd.Series(dtype=float)\n",
    "    gp = df[\"gasPrice\"] if \"gasPrice\" in cols else pd.Series(dtype=float)\n",
    "    gas_used_ratio = (\n",
    "        (df[\"gasUsed\"] / df[\"gas\"]) if {\"gasUsed\", \"gas\"} <= cols else np.array([])\n",
    "    )\n",
    "    features.update(\n",
    "        {\n",
    "            \"total_gas_eth\": g.sum() if not g.empty else 0.0,\n",
    "            \"mean_gas_eth\": g.mean() if not g.empty else 0.0,\n",
    "            \"std_gas_eth\": g.std() if not g.empty else 0.0,\n",
    "            \"mean_gas_price\": gp.mean() if not gp.empty else 0.0,\n",
    "            \"std_gas_price\": gp.std() if not gp.empty else 0.0,\n",
    "            \"gas_used_ratio_mean\": np.nanmean(gas_used_ratio)\n",
    "            if gas_used_ratio.size\n",
    "            else 0.0,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # ===== Ошибки и направления =====\n",
    "    errs = (\n",
    "        df[\"isError\"].astype(int) if \"isError\" in cols else pd.Series(0, index=df.index)\n",
    "    )\n",
    "    features.update({\"tx_errors\": errs.sum(), \"error_ratio\": errs.mean()})\n",
    "    out = df[df[\"from\"].str.lower() == addr]\n",
    "    inc = df[df[\"to\"].str.lower() == addr]\n",
    "    features.update(\n",
    "        {\n",
    "            \"outgoing_tx_count\": len(out),\n",
    "            \"incoming_tx_count\": len(inc),\n",
    "            \"unique_receivers\": out[\"to\"].nunique(),\n",
    "            \"unique_senders\": inc[\"from\"].nunique(),\n",
    "            \"out_in_ratio\": len(out) / len(inc) if len(inc) else np.nan,\n",
    "            \"receiver_per_tx\": out[\"to\"].nunique() / len(out) if len(out) else np.nan,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # ===== Токен-транзакции =====\n",
    "    if {\"tokenSymbol\", \"tokenDecimal\", \"value\"}.issubset(cols):\n",
    "        token_mask = df[\"tokenSymbol\"].notna() & (df[\"tokenDecimal\"] > 0)\n",
    "        tokens = df[token_mask].copy()\n",
    "        if not tokens.empty:\n",
    "            tokens[\"token_value\"] = tokens[\"value\"] / (10 ** tokens[\"tokenDecimal\"])\n",
    "            tv = tokens[\"token_value\"]\n",
    "            features.update(\n",
    "                {\n",
    "                    \"token_tx_count\": len(tokens),\n",
    "                    \"token_tx_ratio\": len(tokens) / tx_count,\n",
    "                    \"total_token_value\": tv.sum(),\n",
    "                    \"mean_token_value\": tv.mean(),\n",
    "                    \"median_token_value\": tv.median(),\n",
    "                    \"std_token_value\": tv.std(),\n",
    "                    \"unique_tokens\": tokens[\"tokenSymbol\"].nunique(),\n",
    "                    \"unique_contracts\": tokens[\"contractAddress\"].nunique(),\n",
    "                }\n",
    "            )\n",
    "        else:\n",
    "            features.update(\n",
    "                {\n",
    "                    k: 0\n",
    "                    for k in [\n",
    "                        \"token_tx_count\",\n",
    "                        \"token_tx_ratio\",\n",
    "                        \"total_token_value\",\n",
    "                        \"mean_token_value\",\n",
    "                        \"median_token_value\",\n",
    "                        \"std_token_value\",\n",
    "                        \"unique_tokens\",\n",
    "                        \"unique_contracts\",\n",
    "                    ]\n",
    "                }\n",
    "            )\n",
    "    else:\n",
    "        features.update(\n",
    "            {\n",
    "                k: 0\n",
    "                for k in [\n",
    "                    \"token_tx_count\",\n",
    "                    \"token_tx_ratio\",\n",
    "                    \"total_token_value\",\n",
    "                    \"mean_token_value\",\n",
    "                    \"median_token_value\",\n",
    "                    \"std_token_value\",\n",
    "                    \"unique_tokens\",\n",
    "                    \"unique_contracts\",\n",
    "                ]\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # ===== Повторы транзакций =====\n",
    "    dup_cols = [\n",
    "        c for c in [\"to\", \"value\", \"gas\", \"gasPrice\", \"functionName\"] if c in cols\n",
    "    ]\n",
    "    dup_count = df.duplicated(subset=dup_cols).sum() if dup_cols else 0\n",
    "    features.update(\n",
    "        {\n",
    "            \"duplicate_tx_count\": dup_count,\n",
    "            \"duplicate_tx_ratio\": dup_count / tx_count if tx_count else 0.0,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # ===== Время суток и типы Tx =====\n",
    "    if \"timeStamp\" in cols:\n",
    "        hours = df[\"timeStamp\"].dt.hour.dropna()\n",
    "        hour_probs = hours.value_counts(normalize=True)\n",
    "        features[\"peak_hour\"] = hour_probs.idxmax() if not hour_probs.empty else np.nan\n",
    "        features[\"peak_hour_ratio\"] = (\n",
    "            hour_probs.max() if not hour_probs.empty else np.nan\n",
    "        )\n",
    "        features[\"hour_entropy\"] = (\n",
    "            -(hour_probs * np.log(hour_probs + 1e-9)).sum()\n",
    "            if not hour_probs.empty\n",
    "            else np.nan\n",
    "        )\n",
    "        features[\"weekend_tx_ratio\"] = (df[\"timeStamp\"].dt.weekday >= 5).mean()\n",
    "    if \"tx_type\" in cols:\n",
    "        type_probs = df[\"tx_type\"].dropna().value_counts(normalize=True)\n",
    "        features[\"unique_tx_types\"] = df[\"tx_type\"].nunique()\n",
    "        features[\"tx_type_entropy\"] = (\n",
    "            -(type_probs * np.log(type_probs + 1e-9)).sum()\n",
    "            if not type_probs.empty\n",
    "            else np.nan\n",
    "        )\n",
    "\n",
    "    # ===== Подтверждения =====\n",
    "    if \"confirmations\" in cols:\n",
    "        conf = df[\"confirmations\"]\n",
    "        features.update(\n",
    "            {\n",
    "                \"confirmations_mean\": conf.mean(),\n",
    "                \"confirmations_std\": conf.std(),\n",
    "                \"low_conf_ratio\": (conf < conf.quantile(0.25)).mean()\n",
    "                if len(conf)\n",
    "                else np.nan,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def process_pickles(folder_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Обходит все .pkl в папке, извлекает признаки для каждого адреса и\n",
    "    возвращает единый DataFrame.\n",
    "    \"\"\"\n",
    "    features_list = []\n",
    "    pkl_files = [f for f in os.listdir(folder_path) if f.endswith(\".pkl\")]\n",
    "    for fname in tqdm(pkl_files, desc=\"Processing files\"):\n",
    "        file_path = os.path.join(folder_path, fname)\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            list_of_dfs = pickle.load(f)\n",
    "\n",
    "        for df in tqdm(list_of_dfs, desc=f\"File {fname}\", leave=False):\n",
    "            if \"address\" not in df.columns:\n",
    "                continue\n",
    "            for addr in df[\"address\"].unique():\n",
    "                subdf = df[df[\"address\"] == addr]\n",
    "                feats = extract_sybil_features_etherscan(subdf)\n",
    "                if feats:\n",
    "                    feats[\"address\"] = addr\n",
    "                    features_list.append(feats)\n",
    "\n",
    "    return pd.DataFrame(features_list)\n",
    "\n",
    "\n",
    "# ===== Пример запуска =====\n",
    "if __name__ == \"__main__\":\n",
    "    folder = \"etherscan_txns\"\n",
    "    all_features_df = process_pickles(folder)\n",
    "    all_features_df.to_pickle(\"etherscan_sybil_features_all_addresses.pickle\")\n",
    "    print(f\"Extracted features for {len(all_features_df)} addresses.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
